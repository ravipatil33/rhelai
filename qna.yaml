version: 3
created_by: ravipatil33
domain: science
seed_examples:
  - context: |
      RHEL AI provides ability to end user to customize base LLMs with synthesized data, fine-tune LLM model.
    questions_and_answers:
      - question: |
          What is RHEL AI?
        answer: |
          RHEL AI empowers to contribute directly to LLMs. Build AI-based applications e.g. chatbots.
      - question: |
          What does Red Hat Enterprise Linux AI allows you to perform ?
        answer: |
          Host an LLM and interact with LLMs, add your own knowledge  and fine-tune a model.
      - question: |
          What are components of RHEL AI ?
        answer: |
          RHEL AI includes: bootc(Image Mode), taxonomy(Knowledge), SDG(data), DeepSpeed(Training), VLLM(Serve Model).
      - question: |
          What are most common pythong libraries used for Deep Learning in RHEL AI ?
        answer: |
          PyTorch, DeepSpeed, Tensor are few of the most common python libraries for deep learning.
      - question: |
          How are InstructLab and RHELAI related ?
        answer: |
          RHEL AI takes InstructLab and builds an enterpise platform to integrate LLM in applications.
  - context: |
      LAB - synthetic data-based fine-tuning method for LLMs. A taxonomy-guided, multi-phase training and fine-tuning.
    questions_and_answers:
      - question: |
          What is LAB ?
        answer: |
          LAB stands for Large-scale Alignment for chatBots, synthentic data is used to fine-tune model.
      - question: |
          What is difference between InstructLab and RHEL AI ?
        answer: |
          RHEL AI targets servers with dedicated GPUs. InstructLab targets laptops and PCs.
      - question: |
          What does RHEL AI and InstructLab allows end customer ?
        answer: |
          RHEL AI and InstructLab allow customizing LLM with domain-specific knowledge for different use cases.
      - question: |
          What should I run in enterprise systems for deploy AI or LLMs in application ?
        answer: |
          RHEL AI tools including bootc, vllm, deepspeed and instructlab.
      - question: |
          Can I train model on Laptop ?
        answer: |
          InstructLab enables users to contribute, modify, fine-tune and train LLM models on Laptop.
  - context: |
      The Red Hat Enterprise Linux AI bootable image contains InstructLab and its tooling.
    questions_and_answers:
      - question: |
          What is LAB ?
        answer: |
          LAB stands for Large-scale Alignment for chatBots, synthesized data is used to fine-tune base model.
      - question: |
          What are steps to customize LLMs using RHEL AI ?
        answer: |
          Install, add knowledge, generate data, train model, evaluate model.
      - question: |
          What is the judge model used for running synthetic data generation (SDG) ?
        answer: |
          The Mixtral-8x-7B-instruct judge model generates synthetic question and answer.
      - question: |
          How does RHEL AI trains the LLM Model ?
        answer: |
          Using the InstructLab with DeepSpeed for multi-phase training the base model.
      - question: |
          What is the teacher model ?
        answer: |
          The prometheus-8x7b-v2-0 teacher model evaluates the data sets for accuracy.
  - context: |
      Hardware requirements to train Granite models includes GPUs, Aggregate GPU memory and disk storage.
    questions_and_answers:
      - question: |
          What is GPUs ?
        answer: |
          GPU stands for Graphical Processing Unit, with ML and DL, it helps to perform fast parallel calculations.
      - question: |
          Who manufactures the GPUs ?
        answer: |
          NVIDIA is major player in GPUs followed by AMD. The most popular models are L40, L40S, A100 and H100.
      - question: |
          What is the best  GPU by NVIDIA for RHEL AI or LLM training ?
        answer: |
          NVIDIA H100 in counts of 2, 4 or 8 with aggregated memory and 1 TB of disk.
      - question: |
          What is A100, H100, L40S and L40 ?
        answer: |
          These are popular GPU models from NVIDIA.
      - question: |
          What does 160GB, 320GB and 640GB means ?
        answer: |
          The values in GB here in multiplication of 160 are representing Aggregate GPU memory.
  - context: |
      Hardware requirements to infere and serve is lower like L40S, L40 with 80 GB disk.
    questions_and_answers:
      - question: |
          What GPUs are okay for serving the model ?
        answer: |
          NVIDIA L40S with 48GB RAM or NVIDIA L40 with 24GB memory is fine to serve model.
      - question: |
          What all components RHEL AI includes ?
        answer: |
          Granite foundation model, InstructLab, bootc, vLLM, deepspeed and PyTorch.
      - question: |
          Is it recommended to run RHEL AI on laptop ?
        answer: |
          No, as RHEL AI requires high resources, it should be run on enterprise server.
      - question: |
          Can InstructLab be deployed on Laptop or PC ?
        answer: |
          Yes
      - question: |
          Is InstructLab open source ?
        answer: |
          Yes
document_outline: |
  Information about RHEL AI including Overview, Installation, Customization and CLI commands for ilab.
document:
  repo: https://github.com/ravipatil33/rhelai/
  commit: 69085a5
  patterns:
    - sampledata.md
